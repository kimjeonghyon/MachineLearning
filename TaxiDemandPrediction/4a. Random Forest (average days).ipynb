{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Configure libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import geohash\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion for cross-validation over a grid of parameters\n",
    "\n",
    "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None, verbose=0):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func, verbose=verbose)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds, verbose=verbose)\n",
    "    gs.fit(X, y)\n",
    "    print \"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_, gs.scorer_\n",
    "    print \"Best score: \", gs.best_score_\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Geohash precision of 6 (geohash length of 6 characters), we have roughly 300,000 records. For a precision of 7, we have about 4 million records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695424, 11)\n"
     ]
    }
   ],
   "source": [
    "# Each line is of the format:\n",
    "# ((time_cat, time_num, time_cos, time_sin, day_cat, day_num, day_cos, day_sin, weekend, geohash), number of pickups)\n",
    "names = [\"time_cat\", \"time_num\", \"time_cos\", \"time_sin\", \"day_cat\", \"day_num\", \"day_cos\", \"day_sin\", \"weekend\", \"geohash\", \"pickups\"]\n",
    "dftaxi=pd.read_csv(\"./data/trainset7.csv\", header=None, names = names)\n",
    "print dftaxi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False,  True, False,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrain, itest = train_test_split(xrange(dftaxi.shape[0]), train_size=0.8)\n",
    "mask=np.ones(dftaxi.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)\n",
    "mask[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final preperation for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried initially doing one-hot-encoding on the geohashes, but I quickly realized that this was not feasible from a memory perspective. 3 million records times 100,000 features would not fit in memory. So I decided to go for the numerical latitude and longitude route. Using a random forest, we can easily detect higher order structures in these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off the features\n",
    "Xnames = [\"time_cat\", \"time_num\", \"time_cos\", \"time_sin\", \"day_cat\",\n",
    "          \"day_num\", \"day_cos\", \"day_sin\", \"weekend\", \"geohash\"]\n",
    "X = dftaxi[Xnames]\n",
    "\n",
    "# Split off the target (which will be the logarithm of the number of pickups (+1))\n",
    "y = np.log10(dftaxi['pickups']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time_cat</th>\n",
       "      <th>time_num</th>\n",
       "      <th>time_cos</th>\n",
       "      <th>time_sin</th>\n",
       "      <th>day_cat</th>\n",
       "      <th>day_num</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>weekend</th>\n",
       "      <th>geohash</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013</th>\n",
       "      <th>10</th>\n",
       "      <th>10</th>\n",
       "      <td>22:30</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.946930</td>\n",
       "      <td>-0.321439</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.563988</td>\n",
       "      <td>-0.920261</td>\n",
       "      <td>-0.391305</td>\n",
       "      <td>0</td>\n",
       "      <td>dr72jhs</td>\n",
       "      <td>40.806656</td>\n",
       "      <td>-73.953781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>1</th>\n",
       "      <td>13:30</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>-0.896873</td>\n",
       "      <td>-0.442289</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.653274</td>\n",
       "      <td>-0.571021</td>\n",
       "      <td>-0.820936</td>\n",
       "      <td>0</td>\n",
       "      <td>dr5rveb</td>\n",
       "      <td>40.758591</td>\n",
       "      <td>-73.937302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00:00</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.997859</td>\n",
       "      <td>0.065403</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0.858631</td>\n",
       "      <td>0.630773</td>\n",
       "      <td>-0.775968</td>\n",
       "      <td>1</td>\n",
       "      <td>dr72r34</td>\n",
       "      <td>40.831375</td>\n",
       "      <td>-73.857651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>17</th>\n",
       "      <td>23:00</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.980785</td>\n",
       "      <td>-0.195090</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.195090</td>\n",
       "      <td>0.980785</td>\n",
       "      <td>0</td>\n",
       "      <td>dr72j6z</td>\n",
       "      <td>40.797043</td>\n",
       "      <td>-73.938675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>26</th>\n",
       "      <td>17:00</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>-0.195090</td>\n",
       "      <td>-0.980785</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>-0.980785</td>\n",
       "      <td>-0.195090</td>\n",
       "      <td>0</td>\n",
       "      <td>dr72r1r</td>\n",
       "      <td>40.832748</td>\n",
       "      <td>-73.861771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time_cat  time_num  time_cos  time_sin   day_cat   day_num   day_cos   day_sin  weekend  geohash   latitude  longitude\n",
       "2013 10 10    22:30  0.947917  0.946930 -0.321439  Thursday  0.563988 -0.920261 -0.391305        0  dr72jhs  40.806656 -73.953781\n",
       "     11 1     13:30  0.572917 -0.896873 -0.442289    Friday  0.653274 -0.571021 -0.820936        0  dr5rveb  40.758591 -73.937302\n",
       "        17    00:00  0.010417  0.997859  0.065403    Sunday  0.858631  0.630773 -0.775968        1  dr72r34  40.831375 -73.857651\n",
       "     9  17    23:00  0.968750  0.980785 -0.195090   Tuesday  0.281250 -0.195090  0.980785        0  dr72j6z  40.797043 -73.938675\n",
       "     12 26    17:00  0.718750 -0.195090 -0.980785  Thursday  0.531250 -0.980785 -0.195090        0  dr72r1r  40.832748 -73.861771"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the longitude and latitude from the geohash\n",
    "def decodegeo(geo, which):\n",
    "    if len(geo) >= 6:\n",
    "        geodecoded = geohash.decode(geo)\n",
    "        return geodecoded[which]\n",
    "    else:\n",
    "        return 0\n",
    "X['latitude'] = X['geohash'].apply(lambda geo: decodegeo(geo, 0))\n",
    "X['longitude'] = X['geohash'].apply(lambda geo: decodegeo(geo, 1))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indicator variables for the hours and days of the week and drop the categorical values\n",
    "# g = 5\n",
    "# X = X.join(pd.get_dummies(X['time_cat']))\\\n",
    "#      .join(pd.get_dummies(X['day_cat']))\\\n",
    "#      .drop(['time_cat','day_cat','geohash'], axis=1)\n",
    "X = X.drop(['time_cat','day_cat','geohash'], axis=1)\n",
    "#     .join(pd.get_dummies(X['geohash'].str[:g]))\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556339, 9)\n"
     ]
    }
   ],
   "source": [
    "n_samples = Xtrain.shape[0]\n",
    "n_features = Xtrain.shape[1]\n",
    "print Xtrain.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Regression estimator\n",
    "estimator = RandomForestRegressor(n_estimators=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step below takes about 25 mins on my laptop for 300,000 records and up to 100 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] max_features=auto, n_estimators=3, max_depth=3 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=3, max_depth=3, score=-0.014398 -   1.8s\n",
      "[CV] max_features=auto, n_estimators=3, max_depth=3 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=3, max_depth=3, score=-0.014356 -   1.7s\n",
      "BEST {'max_features': 'auto', 'n_estimators': 3, 'max_depth': 3} -0.0143772083284 [mean: -0.01438, std: 0.00002, params: {'max_features': 'auto', 'n_estimators': 3, 'max_depth': 3}] make_scorer(mean_squared_error, greater_is_better=False)\n",
      "Best score:  -0.0143772083284\n",
      "CPU times: user 6.21 s, sys: 528 ms, total: 6.74 s\n",
      "Wall time: 5.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define a grid of parameters over which to optimize the random forest\n",
    "# We will figure out which number of trees is optimal\n",
    "parameters = {\"n_estimators\": [3],\n",
    "              \"max_features\": [\"auto\"], # [\"auto\",\"sqrt\",\"log2\"]\n",
    "              \"max_depth\": [3]}\n",
    "best = cv_optimize(estimator, parameters, Xtrain, ytrain, n_folds=2, score_func='mean_squared_error', verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "R^2 on training data: 0.0693\n",
      "R^2 on test data:     0.0668\n"
     ]
    }
   ],
   "source": [
    "# Fit the best Random Forest and calculate R^2 values for training and test sets\n",
    "reg=best.fit(Xtrain, ytrain)\n",
    "training_accuracy = reg.score(Xtrain, ytrain)\n",
    "test_accuracy = reg.score(Xtest, ytest)\n",
    "print \"############# based on standard predict ################\"\n",
    "print \"R^2 on training data: %0.4f\" % (training_accuracy)\n",
    "print \"R^2 on test data:     %0.4f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check on some records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       ...,\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some of the predictions vs. the real number of pickups\n",
    "# predictions vs. real number of pickups\n",
    "np.round(np.power(10,np.column_stack((reg.predict(Xtest),ytest))) - 1,decimals=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.120 (this is in log-space!)\n",
      "So two thirds of the records would be a factor of less than 1.32 away from the real value.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Root Mean Squared Error\n",
    "rmse = np.sqrt(mean_squared_error(reg.predict(Xtest),ytest))\n",
    "print \"RMSE = %0.3f (this is in log-space!)\" % rmse\n",
    "print \"So two thirds of the records would be a factor of less than %0.2f away from the real value.\" % np.power(10,rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('latitude', 0.5951082898372474),\n",
       " ('longitude', 0.40489171016275255),\n",
       " ('time_num', 0.0),\n",
       " ('day_num', 0.0),\n",
       " ('time_cos', 0.0),\n",
       " ('day_cos', 0.0),\n",
       " ('time_sin', 0.0),\n",
       " ('weekend', 0.0),\n",
       " ('day_sin', 0.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most important features?\n",
    "import operator\n",
    "dict_feat_imp = dict(zip(list(X.columns.values),reg.feature_importances_))\n",
    "\n",
    "sorted_features = sorted(dict_feat_imp.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create predictions for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to generate predictions that we can visualize in Tableau. We do this by generating all possible combinations of time and location so that we have a well filled space of predictions. Then we generate predictions for all these combinations and then export to .csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we need a dataframe with all possible combinations of time and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframes with all possible times (time_data) and all possible locations (loc_data)\n",
    "\n",
    "# Columns about time\n",
    "time_cols = list(X.columns.values)\n",
    "time_cols.remove('latitude')\n",
    "time_cols.remove('longitude')\n",
    "\n",
    "# Columns about location\n",
    "loc_cols = ['latitude', 'longitude']\n",
    "\n",
    "# Unique times\n",
    "time_data = X.drop(loc_cols, axis=1).drop_duplicates()\n",
    "\n",
    "# In Tableau we are only going to look at Monday\n",
    "time_data = time_data[time_data['day_num'] <= 1/7.]\n",
    "\n",
    "# Unique locations\n",
    "loc_data = X.drop(time_cols, axis=1).drop_duplicates()\n",
    "\n",
    "# To reduce memory consumption in Tableau, we are only predicting for\n",
    "# the region closely around Manhattan and the La Guardia and JFK airports\n",
    "loc_data = loc_data[(loc_data['latitude'] > 40.5) & (loc_data['latitude'] < 41.1) &\n",
    "                    (loc_data['longitude'] > -74.1) & (loc_data['longitude'] < -73.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy column to be able to join them together\n",
    "time_data['key'] = 1\n",
    "loc_data['key'] = 1\n",
    "\n",
    "# Merge the time_data and location_data\n",
    "result = pd.merge(time_data, loc_data, on='key').drop(['key'], axis=1)\n",
    "result = result[Xtrain.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_num</th>\n",
       "      <th>time_cos</th>\n",
       "      <th>time_sin</th>\n",
       "      <th>day_num</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>weekend</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>681744.000000</td>\n",
       "      <td>6.817440e+05</td>\n",
       "      <td>6.817440e+05</td>\n",
       "      <td>681744.000000</td>\n",
       "      <td>681744.000000</td>\n",
       "      <td>681744.000000</td>\n",
       "      <td>681744</td>\n",
       "      <td>681744.000000</td>\n",
       "      <td>681744.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.401880e-17</td>\n",
       "      <td>-5.402986e-17</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.871039</td>\n",
       "      <td>0.419470</td>\n",
       "      <td>0</td>\n",
       "      <td>40.750763</td>\n",
       "      <td>-73.901631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.288613</td>\n",
       "      <td>7.071073e-01</td>\n",
       "      <td>7.071073e-01</td>\n",
       "      <td>0.041230</td>\n",
       "      <td>0.113335</td>\n",
       "      <td>0.229109</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079246</td>\n",
       "      <td>0.062876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010417</td>\n",
       "      <td>-9.978589e-01</td>\n",
       "      <td>-9.978589e-01</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.630773</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0</td>\n",
       "      <td>40.560837</td>\n",
       "      <td>-74.099350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.255208</td>\n",
       "      <td>-6.824693e-01</td>\n",
       "      <td>-6.824693e-01</td>\n",
       "      <td>0.036458</td>\n",
       "      <td>0.784712</td>\n",
       "      <td>0.227069</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689926</td>\n",
       "      <td>-73.946915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-1.734723e-16</td>\n",
       "      <td>1.318390e-16</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.900929</td>\n",
       "      <td>0.433865</td>\n",
       "      <td>0</td>\n",
       "      <td>40.742111</td>\n",
       "      <td>-73.907089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.744792</td>\n",
       "      <td>6.824693e-01</td>\n",
       "      <td>6.824693e-01</td>\n",
       "      <td>0.106399</td>\n",
       "      <td>0.973845</td>\n",
       "      <td>0.619808</td>\n",
       "      <td>0</td>\n",
       "      <td>40.821762</td>\n",
       "      <td>-73.859024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.989583</td>\n",
       "      <td>9.978589e-01</td>\n",
       "      <td>9.978589e-01</td>\n",
       "      <td>0.141369</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.775968</td>\n",
       "      <td>0</td>\n",
       "      <td>41.096420</td>\n",
       "      <td>-73.606339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_num      time_cos      time_sin        day_num        day_cos        day_sin  weekend       latitude      longitude\n",
       "count  681744.000000  6.817440e+05  6.817440e+05  681744.000000  681744.000000  681744.000000   681744  681744.000000  681744.000000\n",
       "mean        0.500000 -3.401880e-17 -5.402986e-17       0.071429       0.871039       0.419470        0      40.750763     -73.901631\n",
       "std         0.288613  7.071073e-01  7.071073e-01       0.041230       0.113335       0.229109        0       0.079246       0.062876\n",
       "min         0.010417 -9.978589e-01 -9.978589e-01       0.001488       0.630773       0.009350        0      40.560837     -74.099350\n",
       "25%         0.255208 -6.824693e-01 -6.824693e-01       0.036458       0.784712       0.227069        0      40.689926     -73.946915\n",
       "50%         0.500000 -1.734723e-16  1.318390e-16       0.071429       0.900929       0.433865        0      40.742111     -73.907089\n",
       "75%         0.744792  6.824693e-01  6.824693e-01       0.106399       0.973845       0.619808        0      40.821762     -73.859024\n",
       "max         0.989583  9.978589e-01  9.978589e-01       0.141369       0.999956       0.775968        0      41.096420     -73.606339"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_num</th>\n",
       "      <th>time_cos</th>\n",
       "      <th>time_sin</th>\n",
       "      <th>day_num</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>weekend</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>681744.000000</td>\n",
       "      <td>6.817440e+05</td>\n",
       "      <td>6.817440e+05</td>\n",
       "      <td>681744.000000</td>\n",
       "      <td>681744.000000</td>\n",
       "      <td>681744.000000</td>\n",
       "      <td>681744</td>\n",
       "      <td>681744.000000</td>\n",
       "      <td>681744.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.401880e-17</td>\n",
       "      <td>-5.402986e-17</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.871039</td>\n",
       "      <td>0.419470</td>\n",
       "      <td>0</td>\n",
       "      <td>40.750763</td>\n",
       "      <td>-73.901631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.288613</td>\n",
       "      <td>7.071073e-01</td>\n",
       "      <td>7.071073e-01</td>\n",
       "      <td>0.041230</td>\n",
       "      <td>0.113335</td>\n",
       "      <td>0.229109</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079246</td>\n",
       "      <td>0.062876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010417</td>\n",
       "      <td>-9.978589e-01</td>\n",
       "      <td>-9.978589e-01</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.630773</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0</td>\n",
       "      <td>40.560837</td>\n",
       "      <td>-74.099350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.255208</td>\n",
       "      <td>-6.824693e-01</td>\n",
       "      <td>-6.824693e-01</td>\n",
       "      <td>0.036458</td>\n",
       "      <td>0.784712</td>\n",
       "      <td>0.227069</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689926</td>\n",
       "      <td>-73.946915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-1.734723e-16</td>\n",
       "      <td>1.318390e-16</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.900929</td>\n",
       "      <td>0.433865</td>\n",
       "      <td>0</td>\n",
       "      <td>40.742111</td>\n",
       "      <td>-73.907089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.744792</td>\n",
       "      <td>6.824693e-01</td>\n",
       "      <td>6.824693e-01</td>\n",
       "      <td>0.106399</td>\n",
       "      <td>0.973845</td>\n",
       "      <td>0.619808</td>\n",
       "      <td>0</td>\n",
       "      <td>40.821762</td>\n",
       "      <td>-73.859024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.989583</td>\n",
       "      <td>9.978589e-01</td>\n",
       "      <td>9.978589e-01</td>\n",
       "      <td>0.141369</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.775968</td>\n",
       "      <td>0</td>\n",
       "      <td>41.096420</td>\n",
       "      <td>-73.606339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_num      time_cos      time_sin        day_num        day_cos        day_sin  weekend       latitude      longitude\n",
       "count  681744.000000  6.817440e+05  6.817440e+05  681744.000000  681744.000000  681744.000000   681744  681744.000000  681744.000000\n",
       "mean        0.500000 -3.401880e-17 -5.402986e-17       0.071429       0.871039       0.419470        0      40.750763     -73.901631\n",
       "std         0.288613  7.071073e-01  7.071073e-01       0.041230       0.113335       0.229109        0       0.079246       0.062876\n",
       "min         0.010417 -9.978589e-01 -9.978589e-01       0.001488       0.630773       0.009350        0      40.560837     -74.099350\n",
       "25%         0.255208 -6.824693e-01 -6.824693e-01       0.036458       0.784712       0.227069        0      40.689926     -73.946915\n",
       "50%         0.500000 -1.734723e-16  1.318390e-16       0.071429       0.900929       0.433865        0      40.742111     -73.907089\n",
       "75%         0.744792  6.824693e-01  6.824693e-01       0.106399       0.973845       0.619808        0      40.821762     -73.859024\n",
       "max         0.989583  9.978589e-01  9.978589e-01       0.141369       0.999956       0.775968        0      41.096420     -73.606339"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result = result.drop(['pred_pickups'], axis=1)\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the real number of pickups and take care that we can merge it with the predictions,\n",
    "# by also taking the geohash and the timestamp\n",
    "yy = dftaxi[['geohash','day_num','pickups']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Decode the geohash in the latitude and longitude\n",
    "yy['latitude'] = yy['geohash'].apply(lambda geo: decodegeo(geo, 0))\n",
    "yy['longitude'] = yy['geohash'].apply(lambda geo: decodegeo(geo, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions and convert the logarithm to the normal numbers\n",
    "result['pred_pickups'] = np.power(10,reg.predict(result)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result = result.sample(n=100)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = yy.sample (n=100)\n",
    "yy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_num</th>\n",
       "      <th>time_cos</th>\n",
       "      <th>time_sin</th>\n",
       "      <th>day_num</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>weekend</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>pred_pickups</th>\n",
       "      <th>pickups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.980785</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.999607</td>\n",
       "      <td>0.028046</td>\n",
       "      <td>0</td>\n",
       "      <td>40.713272</td>\n",
       "      <td>-73.935928</td>\n",
       "      <td>1.332902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531250</td>\n",
       "      <td>-0.980785</td>\n",
       "      <td>-0.195090</td>\n",
       "      <td>0.075893</td>\n",
       "      <td>0.888446</td>\n",
       "      <td>0.458982</td>\n",
       "      <td>0</td>\n",
       "      <td>40.720139</td>\n",
       "      <td>-73.790359</td>\n",
       "      <td>2.031129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572917</td>\n",
       "      <td>-0.896873</td>\n",
       "      <td>-0.442289</td>\n",
       "      <td>0.081845</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>0.491881</td>\n",
       "      <td>0</td>\n",
       "      <td>40.836868</td>\n",
       "      <td>-73.916702</td>\n",
       "      <td>1.049256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635417</td>\n",
       "      <td>-0.659346</td>\n",
       "      <td>-0.751840</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>0.841713</td>\n",
       "      <td>0.539926</td>\n",
       "      <td>0</td>\n",
       "      <td>40.750351</td>\n",
       "      <td>-73.865891</td>\n",
       "      <td>1.332902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635417</td>\n",
       "      <td>-0.659346</td>\n",
       "      <td>-0.751840</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>0.841713</td>\n",
       "      <td>0.539926</td>\n",
       "      <td>0</td>\n",
       "      <td>40.764084</td>\n",
       "      <td>-73.913956</td>\n",
       "      <td>1.332902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.321439</td>\n",
       "      <td>-0.946930</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.751840</td>\n",
       "      <td>0.659346</td>\n",
       "      <td>0</td>\n",
       "      <td>40.724258</td>\n",
       "      <td>-73.937302</td>\n",
       "      <td>1.332902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.552083</td>\n",
       "      <td>-0.946930</td>\n",
       "      <td>-0.321439</td>\n",
       "      <td>0.078869</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.475515</td>\n",
       "      <td>0</td>\n",
       "      <td>40.724258</td>\n",
       "      <td>-74.001846</td>\n",
       "      <td>1.332902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.751840</td>\n",
       "      <td>0.659346</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.994716</td>\n",
       "      <td>0.102669</td>\n",
       "      <td>0</td>\n",
       "      <td>40.613022</td>\n",
       "      <td>-73.942795</td>\n",
       "      <td>1.100890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.385417</td>\n",
       "      <td>-0.751840</td>\n",
       "      <td>0.659346</td>\n",
       "      <td>0.055060</td>\n",
       "      <td>0.940754</td>\n",
       "      <td>0.339090</td>\n",
       "      <td>0</td>\n",
       "      <td>40.692673</td>\n",
       "      <td>-73.977127</td>\n",
       "      <td>1.100890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>0.980785</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.980785</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>0</td>\n",
       "      <td>40.856094</td>\n",
       "      <td>-73.885117</td>\n",
       "      <td>1.049256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_num  time_cos  time_sin   day_num   day_cos   day_sin  weekend   latitude  longitude  pred_pickups  pickups\n",
       "0  0.031250  0.980785  0.195090  0.004464  0.999607  0.028046        0  40.713272 -73.935928      1.332902      NaN\n",
       "1  0.531250 -0.980785 -0.195090  0.075893  0.888446  0.458982        0  40.720139 -73.790359      2.031129      NaN\n",
       "2  0.572917 -0.896873 -0.442289  0.081845  0.870662  0.491881        0  40.836868 -73.916702      1.049256      NaN\n",
       "3  0.635417 -0.659346 -0.751840  0.090774  0.841713  0.539926        0  40.750351 -73.865891      1.332902      NaN\n",
       "4  0.635417 -0.659346 -0.751840  0.090774  0.841713  0.539926        0  40.764084 -73.913956      1.332902      NaN\n",
       "5  0.802083  0.321439 -0.946930  0.114583  0.751840  0.659346        0  40.724258 -73.937302      1.332902      NaN\n",
       "6  0.552083 -0.946930 -0.321439  0.078869  0.879708  0.475515        0  40.724258 -74.001846      1.332902      NaN\n",
       "7  0.114583  0.751840  0.659346  0.016369  0.994716  0.102669        0  40.613022 -73.942795      1.100890      NaN\n",
       "8  0.385417 -0.751840  0.659346  0.055060  0.940754  0.339090        0  40.692673 -73.977127      1.100890      NaN\n",
       "9  0.218750  0.195090  0.980785  0.031250  0.980785  0.195090        0  40.856094 -73.885117      1.049256      NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Merge the predictions and the real pickups\n",
    "result = pd.merge(result, yy, how='left', on=['day_num', 'latitude', 'longitude']).drop(['geohash'], axis=1)\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns to reduce memory consumption in Tableau\n",
    "result = result.drop(['time_cos','day_num','time_sin','day_cos','day_sin','weekend'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "result.to_csv('./data/taxi-data-predictions_prec_7_monday.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
